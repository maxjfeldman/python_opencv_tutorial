{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This tutorial is a first attempt to create a computer vision training module using OpenCV using Python 3\n",
    "## Written by Max Feldman and Jaebum Park USDA-ARS\n",
    "\n",
    "\n",
    "## This tutorial makes use of many free Python packages you will need to download off the internet\n",
    "## Here is a link to a tutorial of how to get packages/libraries\n",
    "## https://packaging.python.org/tutorials/installing-packages/\n",
    "## Max's favorite package manager is pip\n",
    "\n",
    "## Download\n",
    "\n",
    "## cv2\n",
    "## skimage\n",
    "## numpy\n",
    "## pandas\n",
    "## matplotlib\n",
    "## os\n",
    "## glob\n",
    "## csv\n",
    "## datetime\n",
    "## time\n",
    "## re\n",
    "\n",
    "## Load in the packages needed within the program using 'import'\n",
    "\n",
    "## Image analysis libraries\n",
    "import cv2\n",
    "## OpenCV (cv2) is the workhorse library, it encodes many useful functions that help make image processing easy\n",
    "## In Python, the OpenCV functions are actually links to C functions that perform the heavy lifting\n",
    "## This provides the speed of C and blissful ignorance of Python\n",
    "## Here is a popular OpenCV tutorial\n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html\n",
    "\n",
    "import skimage\n",
    "from skimage import feature\n",
    "## I don't remember why we used the skimage library\n",
    "## Here you are getting a sublibrary of skimage named feature\n",
    "\n",
    "## Import some commonly used arithmatic (numpy), matrix manipulation (pandas), and plotting libraries (matplotlib) in Python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "## using the convention 'as' makes it so you can refer to the encoded functions by an abbreviated name in this case 'pd'\n",
    "import matplotlib.pyplot as plt\n",
    "## in this case 'plt'\n",
    "\n",
    "## Load in some other useful libraries\n",
    "import sys\n",
    "## Variables and functions associated with your operating system\n",
    "import os.path\n",
    "## Directory lookup and access\n",
    "import glob\n",
    "## Use this to get a objects within a directory that matches a text string pattern (aka regular expression)\n",
    "import csv\n",
    "## Functionality to load and write files in .csv format\n",
    "from datetime import date\n",
    "## Manipulation and formatting to match commonly used time stamp formats\n",
    "from time import sleep\n",
    "## sleep is generally used to wait for a period of time while another process is running, commonly used in hardware interfaces/prototyping\n",
    "import re\n",
    "## Regualar expression module (pattern matching)\n",
    "## Here is an intro to regular expression: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First lets get the present working directory using the os.path library getcwd() function\n",
    "pwd = os.getcwd()\n",
    "## Notice the syntax... first the library name (os) then the function (getcwd) seperated by a period\n",
    "## This is how it works in Python, print what was saved to the variable pwd\n",
    "print(pwd)\n",
    "\n",
    "## Now lets make a regular expression to search with...\n",
    "## Here is a tutorial on regular expression in Python\n",
    "## https://docs.python.org/3/howto/regex.html\n",
    "\n",
    "## We are combining (concatenating) the text string saved in 'pwd' with the text string '/black_background_1/*.jpg'\n",
    "infile_query = pwd + \"/black_background_1/*.jpg\"\n",
    "## The symbol \"*\" is a wildcard character that matches anything\n",
    "## So this text string will match any file in this present directory that is a .jpg file\n",
    "print(\"This string is what you are searching for: \")\n",
    "print(infile_query)\n",
    "\n",
    "## Now lets get the file names using the glob function from the glob library\n",
    "files = glob.glob(infile_query)\n",
    "print(files)\n",
    "print(type(files))\n",
    "## This returns a Python list of file names\n",
    "\n",
    "## To sort the entries in the list use the sort function\n",
    "files.sort()\n",
    "## Notice that no new variable is created for the sorted list\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the name of the first image file from the list of images in the current directory you just created\n",
    "## Lets call if 'f'\n",
    "f = files[0]\n",
    "## Note that in Python and Perl the first element of a list is always 0 not 1\n",
    "print(f)\n",
    "\n",
    "## Lets extract the actual name of the image from its file path\n",
    "## Here we are using the split function on the string object named 'f' \n",
    "## We are splitting it up into substrings of text seperated by \"/\"\n",
    "## We are assigning the last substring in that list [-1] to the variable image_name\n",
    "image_name = f.split(\"/\")[-1]\n",
    "print(image_name)\n",
    "\n",
    "## What do you get back if you take the first element of the substring list? \n",
    "print(\"First element of substring list:\")\n",
    "print(f.split(\"/\")[0])\n",
    "## How about the second?\n",
    "\n",
    "## Now lets remove the string \".jpg\" from the name using the Python replace function\n",
    "image_name = image_name.replace(\".jpg\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets load in the image name saved in the variable f\n",
    "\n",
    "## Use the imread function in the cv2 library to load the image named 'f'\n",
    "img = cv2.imread(f)\n",
    "\n",
    "## Lets examine the image using the imshow() function from the matplotlib library\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "## Isn't that odd... the color doesn't seem correct\n",
    "## The reason is that OpenCV has a different default order for the image channels than the camera/sensor used to acquire the image\n",
    "## The default for OpenCV is BGR whereas the actual image is RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets change this using the cvtColor() function in OpenCV\n",
    "imgC = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "## Plot it again\n",
    "plt.imshow(imgC)\n",
    "plt.show()\n",
    "## Looks better no?\n",
    "\n",
    "## Image data is actually a lot like an Excel spreadsheet or a data.frame in R\n",
    "## The x and y coordinates are just the columns and rows, whereas the z coordinate is the channel/sheet (R,G,B) \n",
    "## The values within each matrix span the spectrum between 0 - 255\n",
    "## Low values, those near zero will be darker (black), whereas those near the top end of the spectrum 255 will be white\n",
    "\n",
    "## Here you can get the dimensions of the image using the 'shape' function from the numpy (np) library\n",
    "iy, ix, iz = np.shape(img)\n",
    "print(iy)\n",
    "print(ix)\n",
    "print(iz)\n",
    "# Looks like the image is 4000 x 6000 pixels and has 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets start processing the image\n",
    "\n",
    "## Lets crop the image to remove background/unneccessary features\n",
    "## The syntax for subsetting a matrix/data frame is similar to R but not identical\n",
    "img_crop = imgC[0:1900, 1200:3500]\n",
    "## Try changing the numbers and see what happens...\n",
    "\n",
    "plt.imshow(img_crop)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that we have a good looking image lets start the process of isolating objects of interest\n",
    "\n",
    "## One step commonly used is to blur the image to dampen the influence of small background features (salt-and-pepper noise)\n",
    "## Here we are using a 5 x 5 kernel (window) and blurring it along the x-axis and y-axis 3X standard deviations \n",
    "## More discussion can be found here: \n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "\n",
    "blur = cv2.GaussianBlur(img_crop, (5, 5), 3)\n",
    "## Try increasing the third arguement (3) to a larger number\n",
    "\n",
    "## The next step is to convert this image to different color spaces\n",
    "## Converting to different color spaces can help increase contrast between objects of interest and background\n",
    "\n",
    "## Convert to HSV color space\n",
    "## About HSV:\n",
    "## https://programmingdesignsystems.com/color/color-models-and-color-spaces/index.html\n",
    "imgHSV = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "## Note that imgHSV has the same dimensions as the original image\n",
    "print(\"Dimensions of blurred RGB image:\")\n",
    "print(np.shape(blur))\n",
    "print(\"Dimensions of blurred HSV image:\")\n",
    "print(np.shape(imgHSV))\n",
    "\n",
    "## Convert to LAB\n",
    "## About LAB format:\n",
    "## https://en.wikipedia.org/wiki/CIELAB_color_space\n",
    "imgLAB = cv2.cvtColor(blur, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "## Now we split out each color space into its own image\n",
    "## The resulting image will now be grayscale because it lacks the other channels/dimensions that provide color \n",
    "h, s, v = cv2.split(imgHSV)\n",
    "\n",
    "print(\"The dimesions of the 's' aka 'saturation' channel is:\")\n",
    "print(np.shape(s))\n",
    "\n",
    "print(\"Here is the HSV image:\")\n",
    "plt.imshow(imgHSV)\n",
    "plt.show()\n",
    "\n",
    "print(\"Here is the 's' aka 'saturation' channel/dimension from the HSV image:\")\n",
    "plt.imshow(s)\n",
    "plt.show()\n",
    "\n",
    "## Now just like HSV, split out LAB channels\n",
    "l, a, b = cv2.split(imgLAB)\n",
    "\n",
    "## Also get the individual R, G, B channels by subsetting the 3D matrix\n",
    "## Note the syntax blur[:,:,0] will give all pixels in the first dimension of the matrix\n",
    "r = blur[:, :, 0]\n",
    "g = blur[:, :, 1]\n",
    "bl = blur[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We now have 9 different channels to work with (R,G,BL,H,S,V,L,A,B)\n",
    "## Our main objective is to find channels where good contrast between the tubers (or marker) and background exists\n",
    "\n",
    "## Recall from above the 's' (aka saturation channel looked promising)\n",
    "print(\"The 's' aka 'saturation' channel/dimension from the HSV image shows good contrast:\")\n",
    "plt.imshow(s)\n",
    "plt.show()\n",
    "## Clearly the tubers exhibit different values than the background\n",
    "\n",
    "## This is not the case for all channels\n",
    "print(\"The tubers in the 'h' aka 'hue' channel/dimension from the HSV image shows poor contrast:\")\n",
    "plt.imshow(h)\n",
    "plt.show()\n",
    "\n",
    "## The values within each matrix span the spectrum between 0 - 255\n",
    "## Low values, those near zero will be darker (black), whereas those near the top end of the spectrum (255) will be white\n",
    "## We need to find a number that where if we take everything above that number we get only tubers or only background\n",
    "\n",
    "## One way to do this is look at the distribution of values in the image\n",
    "## Lets plot a histogram of the values in the 's' channel\n",
    "print(\"Here is a histogram of the pixels in the Saturation channel\")\n",
    "plt.hist(s.ravel(), 256)\n",
    "plt.show()\n",
    "## the ravel function applied to object s (s.ravel()) turns the entire 2D matrix into a single list of numbers\n",
    "## then plt.hist makes a histogram of the values that fall into 256 different bins\n",
    "\n",
    "## To me, it looks like there are two peaks, one of values below 50 (likely background) and those between 100-150 (likely tubers)\n",
    "## Can you learn to make a vertical bar at the point where you set the threshold?\n",
    "\n",
    "## Lets try keeping all pixels that exhibit values above 85\n",
    "## This process is called thresholding, assigning all pixels above a certain threshold a value of 1 and all other pixels a value of 0\n",
    "## More information about thresholding can be learned here:\n",
    "## https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html\n",
    "s_ret, s_th = cv2.threshold(s, 85, 255, cv2.THRESH_BINARY)\n",
    "## The variable 's_ret' is the value used (85), whereas the variable 's_th' is the binary image\n",
    "## Value used\n",
    "print(\"Thresholding value used: \")\n",
    "print(s_ret)\n",
    "\n",
    "## Lets look at the resulting binary image\n",
    "## Pixels with value of 1 are yellow/white whereas pixels with value 0 are purple/black\n",
    "print(\"Here is the resulting binary image\")\n",
    "plt.imshow(s_th)\n",
    "plt.show()\n",
    "\n",
    "## Looks like it did an okay job but still picked up a lot of background noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can repeat this for other channels\n",
    "## How about the 'b' channel from the LAB color space?\n",
    "print(\"The tubers in the 'b*' channel/dimension from the LAB image shows good contrast:\")\n",
    "plt.imshow(b)\n",
    "plt.show()\n",
    "## In this case the tubers are darker than the background\n",
    "print(\"Here is a histogram of the pixels in the b* channel\")\n",
    "plt.hist(b.ravel(), 256)\n",
    "plt.show()\n",
    "## Looks like the tubers have values between 90 - 115\n",
    "## Notice how we are using cv2.THRESH_BINARY_INV as the last argument to the cv2.threshold fxn\n",
    "## How does this behavior differ from the thesholding we did on the 's' channel? Why is this needed?\n",
    "b_ret_inv, b_th_inv = cv2.threshold(b, 125, 255, cv2.THRESH_BINARY_INV)\n",
    "print(\"Lets look at how the resulting binary image looks:\")\n",
    "plt.imshow(b_th_inv)\n",
    "plt.show()\n",
    "\n",
    "## Lets use a logical \"AND\" statement to combine these two binary images\n",
    "## Logical \"AND\" means that pixels that exhibit a value of 1 in both images will be assigned a value of 1 \n",
    "## Those with a value of zero in one or both of the binaries will be assigned 0 \n",
    "mask = cv2.bitwise_and(s_th, b_th_inv)\n",
    "\n",
    "print(\"Here is the result of combining both binaries using logical AND\")\n",
    "plt.imshow(mask)\n",
    "plt.show()\n",
    "print(\"Looks okay yes?\")\n",
    "\n",
    "## We can also do the same for the size marker/poker chip\n",
    "marker_ret, marker_th = cv2.threshold(b, 140, 255, cv2.THRESH_BINARY)\n",
    "print(\"We can do the same with the size marker/poker chip\")\n",
    "plt.imshow(marker_th)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now lets use functions to remove background noise and fill in gaps\n",
    "\n",
    "## First make a 5x5 square of ones (kernel) that we will use to perform erosion (shrinking) and then dilation (expansion)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "print(kernel)\n",
    "\n",
    "## Now perform the removal/shrinking/erosion to both binary images (mask and chip)\n",
    "mask_er = cv2.erode(mask, kernel, iterations=1)\n",
    "marker_er = cv2.erode(marker_th, kernel, iterations=1)\n",
    "\n",
    "print(\"Here's the eroded image:\")\n",
    "plt.imshow(mask_er)\n",
    "plt.show()\n",
    "\n",
    "## What happens if you change the number of iterations to 5 or 10?\n",
    "\n",
    "## Now perform the addition/expansion/dilation to both binary images\n",
    "mask_dil = cv2.dilate(mask_er, kernel, iterations=1)\n",
    "marker_dil = cv2.dilate(marker_er, kernel, iterations=1)\n",
    "\n",
    "## What happens if you change the number of iterations to 5 or 10?\n",
    "## What happens if you change the kernel size?\n",
    "\n",
    "print(\"Here's the image after erosion and dilation:\")\n",
    "plt.imshow(mask_dil)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that we have our objects isolated we need to extract a set of points that defines their shape/perimeter\n",
    "## The set of points that comprise the perimeter of an object is called its contour\n",
    "## A good tutorial about contours is here:\n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html\n",
    "\n",
    "## Here we use the OpenCV findContours function \n",
    "## One key argument is the last one cv2.cv2.CHAIN_APPROX_NONE\n",
    "## This specifies to the the function that you want all the points\n",
    "contours, hierarchy = cv2.findContours(mask_dil, cv2.RETR_TREE, cv2.cv2.CHAIN_APPROX_NONE)\n",
    "## The resulting objects are the contours themselves (contours) and a hierarchy (hierarchy) that describes their nesting relationship\n",
    "\n",
    "## Lets get the contours of the size marker too\n",
    "marker_contours, marker_hierarchy = cv2.findContours(marker_dil, cv2.RETR_TREE, cv2.cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now one thing about the variation between images and imperfect processing is that you might end up with a lot of small contours due to background noise\n",
    "## How many contours do you have?\n",
    "print(\"How many contours for potato?\")\n",
    "print(len(contours))\n",
    "\n",
    "## Lets draw them..\n",
    "## First we need to make a copy of the image \n",
    "## Here we are using the copy function from the numpy library\n",
    "contour_img = img_crop.copy()\n",
    "\n",
    "## Use the function draw drawContours\n",
    "## See docuemntation here: \n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contours_begin/py_contours_begin.html\n",
    "\n",
    "## Draw all contours in green\n",
    "print(\"Drawing all potato contours in green...\")\n",
    "contour_img = cv2.drawContours(contour_img, contours, -1, (0,255,0), 5)\n",
    "plt.imshow(contour_img)\n",
    "plt.show()\n",
    "\n",
    "## Are there any properties of the contours you want that will be different than those you'd like to remove?\n",
    "## Size comes to mind...\n",
    "\n",
    "## Look at the binary for the marker \n",
    "\n",
    "print(\"How many contours for marker?\")\n",
    "print(len(marker_contours))\n",
    "\n",
    "## Even if there was more than one object it would likely be the largest one\n",
    "## Thus we can sort the list\n",
    "markerSorted = sorted(marker_contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "## Then take the largest contour\n",
    "marker_contour = markerSorted[0]\n",
    "\n",
    "print(\"Drawing all size marker contours in yellow...\")\n",
    "contour_img = cv2.drawContours(contour_img, [marker_contour], 0, (255,255,0), 5)\n",
    "plt.imshow(contour_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next step is to remove all contours that are not potato and get the correct tuber order\n",
    "## We will do this in a python loop\n",
    "## Here is some documetation about loops in Python:\n",
    "## https://www.learnpython.org/en/Loops\n",
    "\n",
    "## Lets see one in action\n",
    "## First make a list of variables\n",
    "potatoes = ['burbank', 'ranger', 'clearwater', 'norkotah']\n",
    "\n",
    "## The syntax is pretty simple\n",
    "## Python uses spaces to break the code in to blocks, the most common is 4 spaces\n",
    "\n",
    "for p in potatoes:\n",
    "    print('This time the potato is: ')\n",
    "    print(p)\n",
    "    ## Note the nesting structure      \n",
    "    if p == \"clearwater\":\n",
    "        print(\"The 3rd Entry is a \" + p + \" potato.\")\n",
    "\n",
    "## Look okay?\n",
    "## Notice how most of the time like in R \"\" and '' can be used interchangably and strings (\"string\") can be mixed with variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First lets sort the contours by size (the potatoes and size marker will be the biggest)\n",
    "cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "## Now lets keep only the 6 largest objects\n",
    "contours = cntsSorted[0:5]\n",
    "\n",
    "## Lets create some variables to populate within the the loop\n",
    "\n",
    "## This variable (contours_out) will be a list of the contours in the desired order\n",
    "contours_out = []\n",
    "## This variable (it) will be the number of times through the loop\n",
    "it = 0\n",
    "## This variable will contain the centroid of each object (centroid X Y)\n",
    "cXY = []\n",
    "\n",
    "## Here's the for loop in action\n",
    "## Basically, for each contour (cnt) in the list (contours), get the area of the contour\n",
    "## If the area is big enough add it to the object named contours_out\n",
    "## For this contour, calculate some basic properties using OpenCV using the cv2.moments() function\n",
    "## More information about this can be found here:\n",
    "## https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html\n",
    "\n",
    "## After we have the x and y coordinate of the centroid (basically the center of the object)\n",
    "## Associate this information with what the order number the contour is in the list\n",
    "## This will be temporarily saved in a variable named entry and eventually appended to variable cXY\n",
    "for cnt in contours:\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area > 3000:\n",
    "        contours_out.append(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        print(cX)\n",
    "        print(cY)\n",
    "        entry = [it, cX, cY]\n",
    "        print(entry)\n",
    "        cXY.append(entry)\n",
    "        it += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Okay so now we have 5 contours and some basic information about them (order in the contour list, x-coordinate of the centroid, and y-coordinate of the centroid)\n",
    "print(cXY)\n",
    "## Because they are laid out on the imaging surface like reading a book (left-to-right, top-to-bottom) we can put them in the correct order\n",
    "\n",
    "## To sort them lets convert this list into a pandas data.frame \n",
    "## Recall from above pd is the abbreviation we gave to pandas library when we read it in\n",
    "## We'll give the data frame a stupid name like 'df'\n",
    "df = pd.DataFrame(cXY, columns=['cnt', 'cmx', 'cmy'])\n",
    "print(df)\n",
    "\n",
    "## First we will sort the values by centroid on the x-axis\n",
    "df = df.sort_values(by='cmx', ascending=False)\n",
    "## Notice how we can distinctly see the 3 tubers to the right hand side\n",
    "\n",
    "print(\"See how we can extract the 3 tubers from the right hand side based upon their 'cmx' value?\")\n",
    "print(df)\n",
    "plt.imshow(img_crop)\n",
    "plt.show()\n",
    "\n",
    "## Lets get those tubers\n",
    "right_side = df[:3]\n",
    "\n",
    "## Now we can sort the tubers/contours by their centroid value on the y-axis\n",
    "right_side = right_side.sort_values(by='cmy')\n",
    "print(\"Here are the contents of the variable 'right_side':\")\n",
    "print(right_side)\n",
    "\n",
    "## Lets get the tubers on the left now\n",
    "left_side = df[3:5]\n",
    "## Same thing as above but with the left hand side\n",
    "left_side = left_side.sort_values(by='cmy')\n",
    "print(\"Here are the contents of the variable 'left_side':\")\n",
    "print(left_side)\n",
    "\n",
    "## Now lets generate a list of which contour is which\n",
    "\n",
    "## Here we just getting a Python list of the sorted contours\n",
    "cnt_order = right_side['cnt'].tolist()\n",
    "## Now were just appending to the list\n",
    "cnt_order = cnt_order + left_side['cnt'].tolist()\n",
    "cnt_order.append(5)\n",
    "print(cnt_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets plot the contours and see if we're doing okay\n",
    "img_draw = img_crop.copy()\n",
    "## Add the marker_contour to the list of potato contours \n",
    "contours_out.append(marker_contour)\n",
    "it = 0\n",
    "for cnt in contours_out:\n",
    "    img_draw = cv2.drawContours(img_draw, [cnt], 0, (255,255,0), 20)\n",
    "    plt.imshow(img_draw)\n",
    "    plt.show()\n",
    "    print(\"Contour number: \" + str(it))\n",
    "    it += 1\n",
    "\n",
    "## There's more than one way to do it (TMTWDI)\n",
    "img_draw = img_crop.copy()\n",
    "it = 0\n",
    "length = len(contours_out)\n",
    "for i in range(length):\n",
    "    img_draw = cv2.drawContours(img_draw, contours_out, i, (0,255,255), 20)\n",
    "    plt.imshow(img_draw)\n",
    "    plt.show()\n",
    "    print(\"Contour number: \" + str(i))\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets close out this session by writing an image to file:\n",
    "\n",
    "## First lets make a results directory\n",
    "outfile_dir = pwd + \"/results\"\n",
    "os.mkdir(outfile_dir)\n",
    "\n",
    "## This is just a fancy way of making the file path we did above\n",
    "outfile = os.path.join(outfile_dir, \"result_section_1.png\")\n",
    "## We also could have done it like \n",
    "outfile = outfile_dir + \"/result_section_1.png\"\n",
    "\n",
    "## Here you're writing the output, the first argument outfile is where to save it (path) \n",
    "## The second is the image, in this case lets save it bak to BGR so it looks normal when you open it\n",
    "cv2.imwrite(outfile, cv2.cvtColor(img_draw, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How would you adapt this program to work on the image located in /illuminator_1    ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
